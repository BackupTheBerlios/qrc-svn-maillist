<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Qrc-svn] r299 - qrc/trunk/gaym/src
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/qrc-svn/2007-July/index.html" >
   <LINK REL="made" HREF="mailto:qrc-svn%40lists.berlios.de?Subject=Re%3A%20%5BQrc-svn%5D%20r299%20-%20qrc/trunk/gaym/src&In-Reply-To=%3C200707140522.l6E5M5wE004870%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="000226.html">
   <LINK REL="Next"  HREF="000230.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Qrc-svn] r299 - qrc/trunk/gaym/src</H1>
    <B>jblebrun at BerliOS</B> 
    <A HREF="mailto:qrc-svn%40lists.berlios.de?Subject=Re%3A%20%5BQrc-svn%5D%20r299%20-%20qrc/trunk/gaym/src&In-Reply-To=%3C200707140522.l6E5M5wE004870%40sheep.berlios.de%3E"
       TITLE="[Qrc-svn] r299 - qrc/trunk/gaym/src">jblebrun at mail.berlios.de
       </A><BR>
    <I>Sat Jul 14 07:22:12 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="000226.html">[Qrc-svn] r298 - qrc/trunk/gaym/src
</A></li>
        <LI>Next message: <A HREF="000230.html">[Qrc-svn] r300 - in qrc/trunk: . gaym/pixmaps gaym/pixmaps/16	gaym/pixmaps/22 gaym/pixmaps/48 gaym/src
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#229">[ date ]</a>
              <a href="thread.html#229">[ thread ]</a>
              <a href="subject.html#229">[ subject ]</a>
              <a href="author.html#229">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: jblebrun
Date: 2007-07-14 07:22:04 +0200 (Sat, 14 Jul 2007)
New Revision: 299

Added:
   qrc/trunk/gaym/src/url_fetch.c
Log:
Forgot to add new file



Added: qrc/trunk/gaym/src/url_fetch.c
===================================================================
--- qrc/trunk/gaym/src/url_fetch.c	2007-07-14 04:39:22 UTC (rev 298)
+++ qrc/trunk/gaym/src/url_fetch.c	2007-07-14 05:22:04 UTC (rev 299)
@@ -0,0 +1,358 @@
+#include &quot;gaym.h&quot;
+#include &quot;util.h&quot;
+#include &quot;debug.h&quot;
+struct _PurpleUtilFetchUrlData
+{
+	PurpleUtilFetchUrlCallback callback;
+	void *user_data;
+
+	struct
+	{
+		char *user;
+		char *passwd;
+		char *address;
+		int port;
+		char *page;
+
+	} website;
+
+	char *url;
+	int num_times_redirected;
+	gboolean full;
+	char *user_agent;
+	gboolean http11;
+	char *request;
+	gsize request_written;
+	gboolean include_headers;
+
+	PurpleProxyConnectData *connect_data;
+	int fd;
+	guint inpa;
+
+	gboolean got_headers;
+	gboolean has_explicit_data_len;
+	char *webdata;
+	unsigned long len;
+	unsigned long data_len;
+};
+
+/**
+ * The arguments to this function are similar to printf.
+ */
+static void
+purple_util_fetch_url_error(PurpleUtilFetchUrlData *gfud, const char *format, ...)
+{
+	gchar *error_message;
+	va_list args;
+
+	va_start(args, format);
+	error_message = g_strdup_vprintf(format, args);
+	va_end(args);
+
+	gfud-&gt;callback(gfud, gfud-&gt;user_data, NULL, 0, error_message);
+	g_free(error_message);
+	purple_util_fetch_url_cancel(gfud);
+}
+
+static void url_fetch_connect_cb(gpointer url_data, gint source, const gchar *error_message);
+
+static size_t
+parse_content_len(const char *data, size_t data_len)
+{
+	size_t content_len = 0;
+	const char *p = NULL;
+
+	/* This is still technically wrong, since headers are case-insensitive
+	 * [RFC 2616, section 4.2], though this ought to catch the normal case.
+	 * Note: data is _not_ nul-terminated.
+	 */
+	if(data_len &gt; 16) {
+		p = (strncmp(data, &quot;Content-Length: &quot;, 16) == 0) ? data : NULL;
+		if(!p)
+			p = (strncmp(data, &quot;CONTENT-LENGTH: &quot;, 16) == 0)
+				? data : NULL;
+		if(!p) {
+			p = g_strstr_len(data, data_len, &quot;\nContent-Length: &quot;);
+			if (p)
+				p++;
+		}
+		if(!p) {
+			p = g_strstr_len(data, data_len, &quot;\nCONTENT-LENGTH: &quot;);
+			if (p)
+				p++;
+		}
+
+		if(p)
+			p += 16;
+	}
+
+	/* If we can find a Content-Length header at all, try to sscanf it.
+	 * Response headers should end with at least \r\n, so sscanf is safe,
+	 * if we make sure that there is indeed a \n in our header.
+	 */
+	if (p &amp;&amp; g_strstr_len(p, data_len - (p - data), &quot;\n&quot;)) {
+		sscanf(p, &quot;%&quot; G_GSIZE_FORMAT, &amp;content_len);
+		purple_debug_misc(&quot;util&quot;, &quot;parsed %u\n&quot;, content_len);
+	}
+
+	return content_len;
+}
+
+
+static void
+url_fetch_recv_cb(gpointer url_data, gint source, PurpleInputCondition cond)
+{
+	PurpleUtilFetchUrlData *gfud = url_data;
+	int len;
+	char buf[4096];
+	char *data_cursor;
+	gboolean got_eof = FALSE;
+
+	while((len = read(source, buf, sizeof(buf))) &gt; 0) {
+		/* If we've filled up our buffer, make it bigger */
+		if((gfud-&gt;len + len) &gt;= gfud-&gt;data_len) {
+			while((gfud-&gt;len + len) &gt;= gfud-&gt;data_len)
+				gfud-&gt;data_len += sizeof(buf);
+
+			gfud-&gt;webdata = g_realloc(gfud-&gt;webdata, gfud-&gt;data_len);
+		}
+
+		data_cursor = gfud-&gt;webdata + gfud-&gt;len;
+
+		gfud-&gt;len += len;
+
+		memcpy(data_cursor, buf, len);
+
+		gfud-&gt;webdata[gfud-&gt;len] = '\0';
+
+		if(!gfud-&gt;got_headers) {
+			char *tmp;
+
+			/* See if we've reached the end of the headers yet */
+			if((tmp = strstr(gfud-&gt;webdata, &quot;\r\n\r\n&quot;))) {
+				char * new_data;
+				guint header_len = (tmp + 4 - gfud-&gt;webdata);
+				size_t content_len;
+
+				purple_debug_misc(&quot;util&quot;, &quot;Response headers: '%.*s'\n&quot;,
+					header_len, gfud-&gt;webdata);
+
+				/* See if we can find a redirect. */
+				/* GAYM FIX: Don't parse redirects! */
+				//if(parse_redirect(gfud-&gt;webdata, header_len, source, gfud))
+				//	return;
+
+				gfud-&gt;got_headers = TRUE;
+
+				/* No redirect. See if we can find a content length. */
+				content_len = parse_content_len(gfud-&gt;webdata, header_len);
+
+				if(content_len == 0) {
+					/* We'll stick with an initial 8192 */
+					content_len = 8192;
+				} else {
+					gfud-&gt;has_explicit_data_len = TRUE;
+				}
+
+
+				/* If we're returning the headers too, we don't need to clean them out */
+				if(gfud-&gt;include_headers) {
+					gfud-&gt;data_len = content_len + header_len;
+					gfud-&gt;webdata = g_realloc(gfud-&gt;webdata, gfud-&gt;data_len);
+				} else {
+					size_t body_len = 0;
+
+					if(gfud-&gt;len &gt; (header_len + 1))
+						body_len = (gfud-&gt;len - header_len);
+
+					content_len = MAX(content_len, body_len);
+
+					new_data = g_try_malloc(content_len);
+					if(new_data == NULL) {
+						purple_debug_error(&quot;util&quot;,
+								&quot;Failed to allocate %u bytes: %s\n&quot;,
+								content_len, strerror(errno));
+						purple_util_fetch_url_error(gfud,
+								_(&quot;Unable to allocate enough memory to hold &quot;
+								  &quot;the contents from %s.  The web server may &quot;
+								  &quot;be trying something malicious.&quot;),
+								gfud-&gt;website.address);
+
+						return;
+					}
+
+					/* We may have read part of the body when reading the headers, don't lose it */
+					if(body_len &gt; 0) {
+						tmp += 4;
+						memcpy(new_data, tmp, body_len);
+					}
+
+					/* Out with the old... */
+					g_free(gfud-&gt;webdata);
+
+					/* In with the new. */
+					gfud-&gt;len = body_len;
+					gfud-&gt;data_len = content_len;
+					gfud-&gt;webdata = new_data;
+				}
+			}
+		}
+
+		if(gfud-&gt;has_explicit_data_len &amp;&amp; gfud-&gt;len &gt;= gfud-&gt;data_len) {
+			got_eof = TRUE;
+			break;
+		}
+	}
+
+	if(len &lt; 0) {
+		if(errno == EAGAIN) {
+			return;
+		} else {
+			purple_util_fetch_url_error(gfud, _(&quot;Error reading from %s: %s&quot;),
+					gfud-&gt;website.address, strerror(errno));
+			return;
+		}
+	}
+
+	if((len == 0) || got_eof) {
+		gfud-&gt;webdata = g_realloc(gfud-&gt;webdata, gfud-&gt;len + 1);
+		gfud-&gt;webdata[gfud-&gt;len] = '\0';
+
+		gfud-&gt;callback(gfud, gfud-&gt;user_data, gfud-&gt;webdata, gfud-&gt;len, NULL);
+		purple_util_fetch_url_cancel(gfud);
+	}
+}
+
+static void
+url_fetch_send_cb(gpointer data, gint source, PurpleInputCondition cond)
+{
+	PurpleUtilFetchUrlData *gfud;
+	int len, total_len;
+
+	gfud = data;
+
+	total_len = strlen(gfud-&gt;request);
+
+	len = write(gfud-&gt;fd, gfud-&gt;request + gfud-&gt;request_written,
+			total_len - gfud-&gt;request_written);
+
+	if (len &lt; 0 &amp;&amp; errno == EAGAIN)
+		return;
+	else if (len &lt; 0) {
+		purple_util_fetch_url_error(gfud, _(&quot;Error writing to %s: %s&quot;),
+				gfud-&gt;website.address, strerror(errno));
+		return;
+	}
+	gfud-&gt;request_written += len;
+
+	if (gfud-&gt;request_written &lt; total_len)
+		return;
+
+	/* We're done writing our request, now start reading the response */
+	purple_input_remove(gfud-&gt;inpa);
+	gfud-&gt;inpa = purple_input_add(gfud-&gt;fd, PURPLE_INPUT_READ, url_fetch_recv_cb,
+		gfud);
+}
+
+static void
+url_fetch_connect_cb(gpointer url_data, gint source, const gchar *error_message)
+{
+	PurpleUtilFetchUrlData *gfud;
+
+	gfud = url_data;
+	gfud-&gt;connect_data = NULL;
+
+	if (source == -1)
+	{
+		purple_util_fetch_url_error(gfud, _(&quot;Unable to connect to %s: %s&quot;),
+				(gfud-&gt;website.address ? gfud-&gt;website.address : &quot;&quot;), error_message);
+		return;
+	}
+
+	gfud-&gt;fd = source;
+
+	if (!gfud-&gt;request)
+	{
+		if (gfud-&gt;user_agent) {
+			/* Host header is not forbidden in HTTP/1.0 requests, and HTTP/1.1
+			 * clients must know how to handle the &quot;chunked&quot; transfer encoding.
+			 * Purple doesn't know how to handle &quot;chunked&quot;, so should always send
+			 * the Host header regardless, to get around some observed problems
+			 */
+			gfud-&gt;request = g_strdup_printf(
+				&quot;GET %s%s HTTP/%s\r\n&quot;
+				&quot;Connection: close\r\n&quot;
+				&quot;User-Agent: %s\r\n&quot;
+				&quot;Accept: */*\r\n&quot;
+				&quot;Host: %s\r\n\r\n&quot;,
+				(gfud-&gt;full ? &quot;&quot; : &quot;/&quot;),
+				(gfud-&gt;full ? (gfud-&gt;url ? gfud-&gt;url : &quot;&quot;) : (gfud-&gt;website.page ? gfud-&gt;website.page : &quot;&quot;)),
+				(gfud-&gt;http11 ? &quot;1.1&quot; : &quot;1.0&quot;),
+				(gfud-&gt;user_agent ? gfud-&gt;user_agent : &quot;&quot;),
+				(gfud-&gt;website.address ? gfud-&gt;website.address : &quot;&quot;));
+		} else {
+			gfud-&gt;request = g_strdup_printf(
+				&quot;GET %s%s HTTP/%s\r\n&quot;
+				&quot;Connection: close\r\n&quot;
+				&quot;Accept: */*\r\n&quot;
+				&quot;Host: %s\r\n\r\n&quot;,
+				(gfud-&gt;full ? &quot;&quot; : &quot;/&quot;),
+				(gfud-&gt;full ? (gfud-&gt;url ? gfud-&gt;url : &quot;&quot;) : (gfud-&gt;website.page ? gfud-&gt;website.page : &quot;&quot;)),
+				(gfud-&gt;http11 ? &quot;1.1&quot; : &quot;1.0&quot;),
+				(gfud-&gt;website.address ? gfud-&gt;website.address : &quot;&quot;));
+		}
+	}
+
+	purple_debug_misc(&quot;util&quot;, &quot;Request: '%s'\n&quot;, gfud-&gt;request);
+
+	gfud-&gt;inpa = purple_input_add(source, PURPLE_INPUT_WRITE,
+								url_fetch_send_cb, gfud);
+	url_fetch_send_cb(gfud, source, PURPLE_INPUT_WRITE);
+}
+
+
+
+PurpleUtilFetchUrlData *
+gaym_util_fetch_url_request(const char *url, gboolean full,
+		const char *user_agent, gboolean http11,
+		const char *request, gboolean include_headers,
+		PurpleUtilFetchUrlCallback callback, void *user_data)
+{
+	PurpleUtilFetchUrlData *gfud;
+
+	g_return_val_if_fail(url      != NULL, NULL);
+	g_return_val_if_fail(callback != NULL, NULL);
+
+	purple_debug_info(&quot;util&quot;,
+			 &quot;requested to fetch (%s), full=%d, user_agent=(%s), http11=%d\n&quot;,
+			 url, full, user_agent?user_agent:&quot;(null)&quot;, http11);
+
+	gfud = g_new0(PurpleUtilFetchUrlData, 1);
+
+	gfud-&gt;callback = callback;
+	gfud-&gt;user_data  = user_data;
+	gfud-&gt;url = g_strdup(url);
+	gfud-&gt;user_agent = g_strdup(user_agent);
+	gfud-&gt;http11 = http11;
+	gfud-&gt;full = full;
+	gfud-&gt;request = g_strdup(request);
+	gfud-&gt;include_headers = include_headers;
+
+	purple_url_parse(url, &amp;gfud-&gt;website.address, &amp;gfud-&gt;website.port,
+				   &amp;gfud-&gt;website.page, &amp;gfud-&gt;website.user, &amp;gfud-&gt;website.passwd);
+
+	gfud-&gt;connect_data = purple_proxy_connect(NULL, NULL,
+			gfud-&gt;website.address, gfud-&gt;website.port,
+			url_fetch_connect_cb, gfud);
+
+	if (gfud-&gt;connect_data == NULL)
+	{
+		purple_util_fetch_url_error(gfud, _(&quot;Unable to connect to %s&quot;),
+				gfud-&gt;website.address);
+		return NULL;
+	}
+
+	return gfud;
+}
+
+


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="000226.html">[Qrc-svn] r298 - qrc/trunk/gaym/src
</A></li>
	<LI>Next message: <A HREF="000230.html">[Qrc-svn] r300 - in qrc/trunk: . gaym/pixmaps gaym/pixmaps/16	gaym/pixmaps/22 gaym/pixmaps/48 gaym/src
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#229">[ date ]</a>
              <a href="thread.html#229">[ thread ]</a>
              <a href="subject.html#229">[ subject ]</a>
              <a href="author.html#229">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/qrc-svn">More information about the Qrc-svn
mailing list</a><br>
</body></html>
